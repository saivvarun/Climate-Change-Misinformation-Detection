{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Versions of python packages</h4>  <br>json = 2.0.9  <br>csv = 1.0  <br>pd = 1.01  <br>re = 2.2.1  <br>nltk = 3.4.5  <br>sklearn = 0.22.1  <br>nkeras = 2.31  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file path need to be changed to train.json file path of host machine\n",
    "with open(r'/Users/varunsai/Desktop/NLP/project-files/train.json') as json_file: \n",
    "    data = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_data=[]\n",
    "labels=[]\n",
    "for i in range(len(list(text_data))):\n",
    "    textual_data.append(list(text_data)[i]['text'])\n",
    "    labels.append(list(text_data)[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pd.DataFrame(list(zip(textual_data, labels)), \n",
    "               columns =['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1168\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why houston flooding isn‘t a sign of climate c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The U.N. Intergovernmental Panel on Climate Ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bureau Now Sets Strict Limits on Cooling\\nOVER...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dirty Extractive Underbelly of Clean Energ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why climate change seems to have faded from th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  why houston flooding isn‘t a sign of climate c...      1\n",
       "1  The U.N. Intergovernmental Panel on Climate Ch...      1\n",
       "2  Bureau Now Sets Strict Limits on Cooling\\nOVER...      1\n",
       "3  The Dirty Extractive Underbelly of Clean Energ...      1\n",
       "4  why climate change seems to have faded from th...      1"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file path need to be changed to dev.json file path of host machine\n",
    "with open(r'/Users/varunsai/Desktop/NLP/project-files/dev.json') as json_file: \n",
    "    data = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=data.values()\n",
    "\n",
    "textual_data=[]\n",
    "labels=[]\n",
    "for i in range(len(list(text_data))):\n",
    "    textual_data.append(list(text_data)[i]['text'])\n",
    "    labels.append(list(text_data)[i]['label'])\n",
    "\n",
    "dev_data=pd.DataFrame(list(zip(textual_data, labels)), \n",
    "               columns =['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file path need to be changed to test-unlabelled.json file path of host machine\n",
    "with open(r'/Users/varunsai/Desktop/NLP/project-files/test-unlabelled.json') as json_file: \n",
    "    data = json.load(json_file) \n",
    "\n",
    "text_data=data.values()\n",
    "\n",
    "textual_data=[]\n",
    "for i in range(len(list(text_data))):\n",
    "    textual_data.append(list(text_data)[i]['text'])\n",
    "    \n",
    "\n",
    "test_data=pd.DataFrame(textual_data, \n",
    "               columns =['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file path need to be changed to negative_label.json file path of host machine\n",
    "negative_label_data=pd.read_json(r'/Users/varunsai/Desktop/NLP/Final_files/NLP/negative_label.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to over 200 countries attending crucial climat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round of coral bleaching. the greenhouse gas e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if it ends up in landfill, its carbon footprin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perpetrators and caps on prices if they are ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have come together once again at the un climat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  to over 200 countries attending crucial climat...      0\n",
       "1  round of coral bleaching. the greenhouse gas e...      0\n",
       "2  if it ends up in landfill, its carbon footprin...      0\n",
       "3  perpetrators and caps on prices if they are ne...      0\n",
       "4  have come together once again at the un climat...      0"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mds=negative_label_data.append(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "training_mds['text']=training_mds['text'].apply(lambda x:x.lower())\n",
    "test_data['text']=test_data['text'].apply(lambda x:x.lower())\n",
    "dev_data['text']=dev_data['text'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mds['cleaned_text']=training_mds['text'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))\n",
    "test_data['cleaned_text']=test_data['text'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))\n",
    "dev_data['cleaned_text']=dev_data['text'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mds['tokenized_word']=training_mds['cleaned_text'].apply(lambda x:word_tokenize(x))\n",
    "test_data['tokenized_word']=test_data['cleaned_text'].apply(lambda x:word_tokenize(x))\n",
    "dev_data['tokenized_word']=dev_data['cleaned_text'].apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and Lemmatisation\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "training_mds['tokenized_word']=training_mds['tokenized_word'].apply(lambda x: [ps.stem(i) for i in x if not i in stopwords])\n",
    "test_data['tokenized_word']=test_data['tokenized_word'].apply(lambda x: [ps.stem(i) for i in x if not i in stopwords])\n",
    "dev_data['tokenized_word']=dev_data['tokenized_word'].apply(lambda x: [ps.stem(i) for i in x if not i in stopwords])\n",
    "\n",
    "ps = WordNetLemmatizer()\n",
    "training_mds['tokenized_word']=training_mds['tokenized_word'].apply(lambda x: [ps.lemmatize(i) for i in x if not i in stopwords])\n",
    "test_data['tokenized_word']=test_data['tokenized_word'].apply(lambda x: [ps.lemmatize(i) for i in x if not i in stopwords])\n",
    "dev_data['tokenized_word']=dev_data['tokenized_word'].apply(lambda x: [ps.lemmatize(i) for i in x if not i in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mds['processed_text_data']=training_mds['tokenized_word'].apply(lambda x:' '.join(x))\n",
    "test_data['processed_text_data']=test_data['tokenized_word'].apply(lambda x:' '.join(x))\n",
    "dev_data['processed_text_data']=dev_data['tokenized_word'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countvectorizer\n",
    "\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = training_mds['processed_text_data']\n",
    "train_y = training_mds['label']\n",
    "test_x = test_data['processed_text_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_initial=cv.fit_transform(train_x)\n",
    "testing_data_initial=cv.transform(test_x)\n",
    "dev_data_final=cv.transform(dev_data['processed_text_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(training_data_initial,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_prediction=lr.predict(testing_data_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_prediction=pd.DataFrame(logreg_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1185\n",
       "0     225\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_test_prediction.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting on validation data\n",
    "prediction_validation=lr.predict(dev_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.71      0.18         7\n",
      "           1       0.96      0.52      0.67        93\n",
      "\n",
      "    accuracy                           0.53       100\n",
      "   macro avg       0.53      0.62      0.42       100\n",
      "weighted avg       0.90      0.53      0.64       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  2],\n",
       "       [45, 48]])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_results = classification_report(prediction_validation, dev_data['label'])\n",
    "print(logreg_results)\n",
    "confusion_matrix(prediction_validation,dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC(kernel='sigmoid')\n",
    "svm.fit(training_data_initial,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction=svm.predict(testing_data_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_prediction=pd.DataFrame(svm_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1201\n",
       "0     209\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_test_prediction.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting on validation data\n",
    "prediction_validation=svm.predict(dev_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.89      0.27         9\n",
      "           1       0.98      0.54      0.70        91\n",
      "\n",
      "    accuracy                           0.57       100\n",
      "   macro avg       0.57      0.71      0.48       100\n",
      "weighted avg       0.91      0.57      0.66       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1],\n",
       "       [42, 49]])"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results = classification_report(prediction_validation, dev_data['label'])\n",
    "print(svm_results)\n",
    "confusion_matrix(prediction_validation,dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1201\n",
       "0     209\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_test_prediction=pd.DataFrame(svm_test_prediction)\n",
    "svm_test_prediction.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14845\n"
     ]
    }
   ],
   "source": [
    "input_dim = training_data_initial.shape[1]\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 10)                148460    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 148,471\n",
      "Trainable params: 148,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_data_initial, train_y,\n",
    "                    epochs=100,\n",
    "                    verbose=False,\n",
    "                    validation_data=(dev_data_final, dev_data['label']),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(training_data_initial, train_y, verbose=False)\n",
    "print(\"Training Accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_validation=model.predict_classes(dev_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.58      0.32        19\n",
      "           1       0.84      0.52      0.64        81\n",
      "\n",
      "    accuracy                           0.53       100\n",
      "   macro avg       0.53      0.55      0.48       100\n",
      "weighted avg       0.72      0.53      0.58       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11,  8],\n",
       "       [39, 42]])"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_results = classification_report(final_prediction_validation, dev_data['label'])\n",
    "print(nn_results)\n",
    "confusion_matrix(final_prediction_validation,dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction=model.predict_classes(testing_data_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction=pd.DataFrame(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    968\n",
       "0    442\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = {}\n",
    "for i in range(0,len(final_prediction)):\n",
    "    key = \"test-\"+str(i)\n",
    "    test_id[key] = {}\n",
    "    label_dict = {}\n",
    "    label_key = \"label\"\n",
    "    label_dict[label_key] = int(final_prediction[0][i])\n",
    "    test_id[key] = label_dict\n",
    "with open(r'/Users/varunsai/Desktop/test-output.json', 'w') as outfile:\n",
    "    json.dump(test_id, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
